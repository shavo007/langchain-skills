# AGENTS.md

Guidelines for AI coding agents working on the langchain-skills project.

## Project overview

This project demonstrates **progressive disclosure** - a context management pattern for LangChain agents. Instead of loading all information upfront, agents see lightweight skill descriptions in the system prompt and load full content (database schemas, business logic) on-demand via tool calls.

**Core architecture**:
- `src/skills_agent/skills.py` - Skill registry and `load_skill` tool
- `src/skills_agent/middleware.py` - System prompt injection via `SkillMiddleware`
- `src/skills_agent/agent.py` - Agent factory functions
- `main.py` - Entry point and example usage

## Dev environment

- Python >=3.11 required
- Use `uv` package manager (not pip)
- Install deps: `uv sync`
- Add packages: `uv add "package-name"`
- Run: `uv run main.py`

Environment variables (`.env`):
```
USE_OPENAI=true
OPENAI_API_KEY=sk-...
LANGSMITH_API_KEY=lsv2_...   # optional, for tracing
LANGSMITH_TRACING=true       # optional
```

## Code style

- Formatter: Ruff (auto-formats on save in VS Code)
- No strict type checking - uses TypedDict for skill definitions
- Follow existing import order: typing → langchain → local
- Add docstrings to public functions
- Keep functions small and focused

## Adding new skills

Edit `src/skills_agent/skills.py` and add to the `SKILLS` list:

```python
Skill(
    name="skill_name",
    description="Brief 1-2 sentence description (shown in system prompt)",
    content="""
    Full detailed content loaded on-demand:
    - Database schemas
    - Business logic rules
    - SQL examples
    """
)
```

Key principle: Keep `description` lightweight, put details in `content`.

## Testing

No automated test framework configured. Current workflow:
- Run example: `uv run main.py`
- Check LangSmith traces for agent behavior (if enabled)
- Syntax check: `python3 -m py_compile src/skills_agent/*.py`

## Common tasks

| Task | Command/Location |
|------|------------------|
| Add dependency | `uv add "package"` |
| Update lock file | `uv sync` |
| Run linter | Automatic via VS Code Ruff extension |
| Debug agent | Enable `LANGSMITH_TRACING=true` in `.env` |
| Change system prompt | Modify `create_skills_agent()` in `agent.py` |
| Add tools | Extend `SkillMiddleware.tools` list in `middleware.py` |

## Architecture notes

**Progressive disclosure flow**:
1. `SkillMiddleware` injects skill descriptions into system message
2. Agent receives user query and identifies relevant skill
3. Agent calls `load_skill("skill_name")` tool
4. Full schema/content returned for that skill only
5. Agent uses loaded context to generate response

**Key classes**:
- `Skill` (TypedDict) - name, description, content
- `SkillMiddleware` - Injects skills into prompts, exposes `load_skill` tool
- `InMemorySaver` - Conversation state persistence per thread

## Security considerations

- Never commit `.env` file with API keys
- The `load_skill` tool returns error messages listing available skills - acceptable for internal use but consider limiting in production
- SQL queries are generated by LLM - validate before execution in real systems
